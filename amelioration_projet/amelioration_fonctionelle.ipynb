{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Création d'une base de données SQL**\n",
    "![alt text](diagram_db.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Create the SQL database\n",
    "def create_db() -> int:\n",
    "    try:\n",
    "        summaries = pd.read_csv('commonlit-evaluate-student-summaries/summaries_train.csv')\n",
    "        prompt = pd.read_csv('commonlit-evaluate-student-summaries/prompts_train.csv')\n",
    "        conn = sqlite3.connect('database.db')\n",
    "        summaries.to_sql('summaries', conn, if_exists='replace', index=False)\n",
    "        prompt.to_sql('prompt', conn, if_exists='replace', index=False)\n",
    "        conn.close()\n",
    "        print(\"Database successfuly created\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occured: {e}\")\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "# Read the content of a table from a request\n",
    "def read_table(request : str) -> list:\n",
    "    conn = sqlite3.connect('database.db')\n",
    "    c = conn.cursor()\n",
    "    results = c.execute(request).fetchall()\n",
    "    conn.close()\n",
    "    return results\n",
    "\n",
    "# Insert rows into the summaries table\n",
    "def add_to_summaries(data : dict | pd.DataFrame) -> int:\n",
    "    try:\n",
    "        data = list(pd.DataFrame(data).itertuples(index=False, name=None))\n",
    "        conn = sqlite3.connect('database.db')\n",
    "        c = conn.cursor()\n",
    "        c.executemany(\"INSERT INTO summaries VALUES (?, ?, ?, ?, ?)\", data)\n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "        print(\"Data imported to database\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occured: {e}\")\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "# Insert rows into the prompts table\n",
    "def add_to_prompt(data: dict | pd.DataFrame) -> int:\n",
    "    try:\n",
    "        data = list(pd.DataFrame(data).itertuples(index=False, name=None))\n",
    "        conn = sqlite3.connect('database.db')\n",
    "        c = conn.cursor()\n",
    "        c.executemany(\"INSERT INTO prompts VALUES (?, ?, ?, ?)\", data)\n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "        print(\"Data imported to database\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occured: {e}\")\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database successfuly created\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('39c16e',\n",
       "  'Summarize at least 3 elements of an ideal tragedy, as described by Aristotle.',\n",
       "  'On Tragedy',\n",
       "  'Chapter 13 \\r\\nAs the sequel to what has already been said, we must proceed to consider what the poet should aim at, and what he should avoid, in constructing his plots; and by what means the specific effect of Tragedy will be produced. \\r\\nA perfect tragedy should, as we have seen, be arranged not on the simple but on the complex plan. It should, moreover, imitate actions which excite pity and fear, this being the distinctive mark of tragic imitation. It follows plainly, in the first place, that the change of fortune presented must not be the spectacle of a virtuous man brought from prosperity to adversity: for this moves neither pity nor fear; it merely shocks us. Nor, again, that of a bad man passing from adversity to prosperity: for nothing can be more alien to the spirit of Tragedy; it possesses no single tragic quality; it neither satisfies the moral sense nor calls forth pity or fear. Nor, again, should the downfall of the utter villain be exhibited. A plot of this kind would, doubtless, satisfy the moral sense, but it would inspire neither pity nor fear; for pity is aroused by unmerited misfortune, fear by the misfortune of a man like ourselves. Such an event, therefore, will be neither pitiful nor terrible. There remains, then, the character between these two extremes — that of a man who is not eminently good and just, yet whose misfortune is brought about not by vice or depravity, but by some error of judgement or frailty. He must be one who is highly renowned and prosperous — a personage like Oedipus, Thyestes, or other illustrious men of such families. \\r\\nA well-constructed plot should, therefore, be single in its issue, rather than double as some maintain. The change of fortune should be not from bad to good, but, reversely, from good to bad. It should come about as the result not of vice, but of some great error or frailty, in a character either such as we have described, or better rather than worse. The practice of the stage bears out our view. At first the poets recounted any legend that came in their way. Now, the best tragedies are founded on the story of a few houses — on the fortunes of Alcmaeon, Oedipus, Orestes, Meleager, Thyestes, Telephus, and those others who have done or suffered something terrible. A tragedy, then, to be perfect according to the rules of art, should be of this construction. Hence they are in error who censure Euripides just because he follows this principle in his plays, many of which end unhappily. It is, as we have said, the right ending. The best proof is that on the stage and in dramatic competition, such plays, if well worked out, are the most tragic in effect; and Euripides, faulty though he may be in the general management of his subject, yet is felt to be the most tragic of the poets. \\r\\nIn the second rank comes the kind of tragedy which some place first. Like the Odyssey, it has a double thread of plot, and also an opposite catastrophe for the good and for the bad. It is accounted the best because of the weakness of the spectators; for the poet is guided in what he writes by the wishes of his audience. The pleasure, however, thence derived is not the true tragic pleasure. It is proper rather to Comedy, where those who, in the piece, are the deadliest enemies — like Orestes and Aegisthus — quit the stage as friends at the close, and no one slays or is slain.'),\n",
       " ('3b9047',\n",
       "  'In complete sentences, summarize the structure of the ancient Egyptian system of government. How were different social classes involved in this government? Cite evidence from the text.',\n",
       "  'Egyptian Social Structure',\n",
       "  'Egyptian society was structured like a pyramid. At the top were the gods, such as Ra, Osiris, and Isis. Egyptians believed that the gods controlled the universe. Therefore, it was important to keep them happy. They could make the Nile overflow, cause famine, or even bring death. \\r\\nThe Egyptians also elevated some human beings to gods. Their leaders, called pharaohs, were believed to be gods in human form. They had absolute power over their subjects. After pharaohs died, huge stone pyramids were built as their tombs. Pharaohs were buried in chambers within the pyramids. \\r\\nBecause the people of Egypt believed that their pharaohs were gods, they entrusted their rulers with many responsibilities. Protection was at the top of the list. The pharaoh directed the army in case of a foreign threat or an internal conflict. All laws were enacted at the discretion of the pharaoh. Each farmer paid taxes in the form of grains, which were stored in the pharaoh’s warehouses. This grain was used to feed the people in the event of a famine. \\r\\nThe Chain of Command \\r\\nNo single person could manage all these duties without assistance. The pharaoh appointed a chief minister called a vizier as a supervisor. The vizier ensured that taxes were collected. \\r\\nWorking with the vizier were scribes who kept government records. These high-level employees had mastered a rare skill in ancient Egypt — they could read and write. \\r\\nNoble Aims \\r\\nRight below the pharaoh in status were powerful nobles and priests. Only nobles could hold government posts; in these positions they profited from tributes paid to the pharaoh. Priests were responsible for pleasing the gods. \\r\\nNobles enjoyed great status and also grew wealthy from donations to the gods. All Egyptians—from pharaohs to farmers—gave gifts to the gods. \\r\\nSoldier On \\r\\nSoldiers fought in wars or quelled domestic uprisings. During long periods of peace, soldiers also supervised the peasants, farmers, and slaves who were involved in building such structures as pyramids and palaces. \\r\\nSkilled workers such as physicians and craftsmen/women made up the middle class. Craftsmen made and sold jewelry, pottery, papyrus products, tools, and other useful things. \\r\\nNaturally, there were people needed to buy goods from artisans and traders. These were the merchants and storekeepers who sold these goods to the public. \\r\\nThe Bottom of the Heap \\r\\nAt the bottom of the social structure were slaves and farmers. Slavery became the fate of those captured as prisoners of war. In addition to being forced to work on building projects, slaves toiled at the discretion of the pharaoh or nobles. \\r\\nFarmers tended the fields, raised animals, kept canals and reservoirs in good order, worked in the stone quarries, and built the royal monuments. Farmers paid taxes that could amount to as much as 60% of their yearly harvest—that’s a lot of hay! \\r\\nSocial mobility was not impossible. A small number of peasants and farmers moved up the economic ladder. Families saved money to send their sons to village schools to learn trades. These schools were run by priests or by artisans. Boys who learned to read and write could become scribes, then go on to gain employment in the government. It was possible for a boy born on a farm to work his way up into the higher ranks of the government. Bureaucracy proved lucrative.'),\n",
       " ('814d6b',\n",
       "  'Summarize how the Third Wave developed over such a short period of time and why the experiment was ended.',\n",
       "  'The Third Wave',\n",
       "  'Background \\r\\nThe Third Wave experiment took place at Cubberley High School in Palo Alto, California during the first week of April 1967. History teacher Ron Jones, finding himself unable to explain to his students how people throughout history followed the crowd even when terrible things were happening, decided to demonstrate it to his students through an experiment. Jones announced that he was starting a movement aimed to eliminate democracy. Jones named the movement “The Third Wave” as a symbol of strength, referring to the mythical belief that the third in a series of waves is the strongest. One of the central points of this movement was that democracy’s main weakness is that it favors the individual over the whole community. Jones emphasized this main point of the movement when he created this catchy motto: “Strength through discipline, strength through community, strength through action, strength through pride.” \\r\\nThe Experiment \\r\\nJones started the first day of the experiment emphasizing simple things like proper seating, and drilled the students extensively until they got it right. He then proceeded to enforce strict classroom discipline by emerging as an authoritarian figure. This resulted in dramatic improvements to the efficiency, or orderliness, of the class.  The first day’s session ended with only a few rules. Jones intended it to be a one-day experiment. Students had to be sitting at attention before the second bell, had to stand up to ask or answer questions and had to do it in three words or fewer, and were required to preface each remark with “Mr. Jones.” As the week went on, Jones’ class transformed into a group with a supreme sense of discipline and community. Jones made up a salute resembling that of the Nazi regime and ordered class members to salute each other even outside the class. They all obeyed this command. \\r\\nAfter only three days, the experiment took on a life of its own, with students from all over the school joining in. The class expanded from initial 30 students to 43 attendees. All of the students showed drastic improvement in their academic skills and tremendous motivation. All of the students were issued a member card and each of them received a special assignment, like designing a Third Wave Banner, stopping non-members from entering the class, or other tasks to bring honor to the movement. Jones instructed the students on how to initiate new members, and by the end of the day the movement had over 200 participants. Jones was surprised that some of the students started reporting to him when other members of the movement failed to abide by the rules. \\r\\nBy the fourth day of the experiment, the students became increasingly involved in the project and their discipline and loyalty to the project was so outstanding that Jones felt it was slipping out of control. He decided to terminate the movement, so he lied to students by announcing that the Third Wave was a part of a nationwide movement and that on the next day a presidential candidate of the movement would publicly announce its existence on television. Jones ordered students to attend a noon rally on Friday to witness the announcement. \\r\\nAt the end of the week, instead of a televised address of their leader, the students were presented with a blank channel. After a few minutes of waiting, Jones announced that they had been a part of an experiment to demonstrate how people willingly create a sense of superiority over others, and how this can lead people to justify doing horrible things in the name of the state’s honor.'),\n",
       " ('ebad26',\n",
       "  'Summarize the various ways the factory would use or cover up spoiled meat. Cite evidence in your answer.',\n",
       "  'Excerpt from The Jungle',\n",
       "  'With one member trimming beef in a cannery, and another working in a sausage factory, the family had a first-hand knowledge of the great majority of Packingtown swindles. For it was the custom, as they found, whenever meat was so spoiled that it could not be used for anything else, either to can it or else to chop it up into sausage. With what had been told them by Jonas, who had worked in the pickle rooms, they could now study the whole of the spoiled-meat industry on the inside, and read a new and grim meaning into that old Packingtown jest—that they use everything of the pig except the squeal. \\r\\nJonas had told them how the meat that was taken out of pickle would often be found sour, and how they would rub it up with soda to take away the smell, and sell it to be eaten on free-lunch counters; also of all the miracles of chemistry which they performed, giving to any sort of meat, fresh or salted, whole or chopped, any color and any flavor and any odor they chose. In the pickling of hams they had an ingenious apparatus, by which they saved time and increased the capacity of the plant—a machine consisting of a hollow needle attached to a pump; by plunging this needle into the meat and working with his foot, a man could fill a ham with pickle in a few seconds. And yet, in spite of this, there would be hams found spoiled, some of them with an odor so bad that a man could hardly bear to be in the room with them. To pump into these the packers had a second and much stronger pickle which destroyed the odor—a process known to the workers as “giving them thirty per cent.” Also, after the hams had been smoked, there would be found some that had gone to the bad. Formerly these had been sold as “Number Three Grade,” but later on some ingenious person had hit upon a new device, and now they would extract the bone, about which the bad part generally lay, and insert in the hole a white-hot iron. After this invention there was no longer Number One, Two, and Three Grade—there was only Number One Grade. The packers were always originating such schemes—they had what they called “boneless hams,” which were all the odds and ends of pork stuffed into casings; and “California hams,” which were the shoulders, with big knuckle joints, and nearly all the meat cut out; and fancy “skinned hams,” which were made of the oldest hogs, whose skins were so heavy and coarse that no one would buy them—that is, until they had been cooked and chopped fine and labeled “head cheese!” \\r\\nIt was only when the whole ham was spoiled that it came into the department of Elzbieta. Cut up by the two-thousand-revolutions- a-minute flyers, and mixed with half a ton of other meat, no odor that ever was in a ham could make any difference. There was never the least attention paid to what was cut up for sausage; there would come all the way back from Europe old sausage that had been rejected, and that was moldy and white – it would be dosed with borax and glycerin, and dumped into the hoppers, and made over again for home consumption. \\r\\nThere would be meat that had tumbled out on the floor, in the dirt and sawdust, where the workers had tramped and spit uncounted billions of consumption germs. There would be meat stored in great piles in rooms; and the water from leaky roofs would drip over it, and thousands of rats would race about on it. It was too dark in these storage places to see well, but a man could run his hand over these piles of meat and sweep off handfuls of the dried dung of rats. These rats were nuisances, and the packers would put poisoned bread out for them; they would die, and then rats, bread, and meat would go into the hoppers together. This is no fairy story and no joke; the meat would be shoveled into carts, and the man who did the shoveling would not trouble to lift out a rat even when he saw one – there were things that went into the sausage in comparison with which a poisoned rat was a tidbit. \\r\\nThere was no place for the men to wash their hands before they ate their dinner, and so they made a practice of washing them in the water that was to be ladled into the sausage. There were the butt-ends of smoked meat, and the scraps of corned beef, and all the odds and ends of the waste of the plants, that would be dumped into old barrels in the cellar and left there. Under the system of rigid economy which the packers enforced, there were some jobs that it only paid to do once in a long time, and among these was the cleaning out of the waste barrels. Every spring they did it; and in the barrels would be dirt and rust and old nails and stale water – and cartload after cartload of it would be taken up and dumped into the hoppers with fresh meat, and sent out to the public\\'s breakfast. Some of it they would make into \"smoked\" sausage – but as the smoking took time, and was therefore expensive, they would call upon their chemistry department, and preserve it with borax and color it with gelatin to make it brown. All of their sausage came out of the same bowl, but when they came to wrap it they would stamp some of it \"special,\" and for this they would charge two cents more a pound.')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "request = \"SELECT * FROM prompt\"\n",
    "read_table(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('000e8c3c7ddb',\n",
       "  '814d6b',\n",
       "  'The third wave was an experimentto see how people reacted to a new one leader government. It gained popularity as people wanted to try new things. The students follow anything that is said and start turning on eachother to gain higher power. They had to stop the experement as too many people got to radical with it blindly following there leader',\n",
       "  0.205682506482641,\n",
       "  0.380537638762288),\n",
       " ('0020ae56ffbf',\n",
       "  'ebad26',\n",
       "  'They would rub it up with soda to make the smell go away and it wouldnt be a bad smell. Some of the meat would be tossed on the floor where there was sawdust spit of the workers and they would make the meat all over again with the things in it.',\n",
       "  -0.548304076980462,\n",
       "  0.506755353548534)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "request = \"SELECT * FROM summaries LIMIT 2\"\n",
    "read_table(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data imported to database\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    'student_id' : ['bad_student', 'good_student'],\n",
    "    'prompt_id' : ['39c16e', '39c16e'],\n",
    "    'text' : ['This is not a very good summary', 'This is a very good summary'],\n",
    "    'content' : [0, 3],\n",
    "    'wording' : [0, 3]\n",
    "    }\n",
    "\n",
    "add_to_summaries(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bad_student', '39c16e', 'This is not a very good summary', 0.0, 0.0),\n",
       " ('good_student', '39c16e', 'This is a very good summary', 3.0, 3.0)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "request = \"SELECT * FROM summaries WHERE student_id LIKE '%student'\"\n",
    "read_table(request)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Mise en place de tests unitaires**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pytest\n",
    "import ipytest\n",
    "\n",
    "from feature_engineering import *\n",
    "\n",
    "ipytest.autoconfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                                            [100%]\u001b[0m\n",
      "\u001b[32m\u001b[32m\u001b[1m17 passed\u001b[0m\u001b[32m in 0.11s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest\n",
    "\n",
    "def test_relative_length():\n",
    "    df = pd.DataFrame({\n",
    "        'prompt_id': ['1', '2', '3'],\n",
    "        'prompt': ['abc', 'defg', 'h']\n",
    "    })\n",
    "    assert relative_length(df, '1', 3) == 1.0\n",
    "    assert relative_length(df, '2', 4) == 1.0\n",
    "    assert relative_length(df, '3', 1) == 1.0\n",
    "    with pytest.raises(IndexError):\n",
    "        relative_length(df, '4', 1)\n",
    "\n",
    "def test_count_stopwords():\n",
    "    assert count_stopwords(\"This is a test.\") == 3\n",
    "    assert count_stopwords(\"No stop words here.\") == 1\n",
    "    assert count_stopwords(\"\") == 0\n",
    "    assert count_stopwords(\"The quick brown fox jumps over the lazy dog.\") == 3\n",
    "    with pytest.raises(AttributeError):\n",
    "        count_stopwords(123)\n",
    "\n",
    "def test_count_punctuation():\n",
    "    assert count_punctuation(\"Hello, world!\") == 2\n",
    "    assert count_punctuation(\"No punctuation here\") == 0\n",
    "    assert count_punctuation(\"\") == 0\n",
    "    assert count_punctuation(\"!#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"+'\"') == 32\n",
    "    with pytest.raises(TypeError):\n",
    "        count_punctuation(123)\n",
    "\n",
    "def test_count_numbers():\n",
    "    assert count_numbers(\"123 abc 456\") == 2\n",
    "    assert count_numbers(\"No numbers here\") == 0\n",
    "    assert count_numbers(\"\") == 0\n",
    "    assert count_numbers(\"1234567890\") == 1\n",
    "    with pytest.raises(TypeError):\n",
    "        count_numbers(123)\n",
    "\n",
    "def test_lemmatize_text():\n",
    "    assert lemmatize_text(\"He is running.\") == ['run']\n",
    "    assert lemmatize_text(\"No stop words here.\") == ['stop', 'word']\n",
    "    assert lemmatize_text(\"\") == []\n",
    "    assert lemmatize_text(\"The quick brown fox jumps over the lazy dog.\") == ['quick', 'brown', 'fox', 'jump', 'lazy', 'dog']\n",
    "    with pytest.raises(AttributeError):\n",
    "        lemmatize_text(123)\n",
    "\n",
    "def test_lemmatize():\n",
    "    df = pd.DataFrame({\n",
    "        'text1': ['He is running.', 'No stop words here.', '', 'The quick brown fox jumps over the lazy dog.'],\n",
    "        'text2': ['Another text.', 'More words here.', 'Empty string.', 'A sentence with punctuation!']\n",
    "    })\n",
    "    df_result = lemmatize(df, ['text1', 'text2'])\n",
    "    assert df_result['text1_lemmatized'].tolist() == [['run'], ['stop', 'word'], [], ['quick', 'brown', 'fox', 'jump', 'lazy', 'dog']]\n",
    "    assert df_result['text2_lemmatized'].tolist() == [['another', 'text'], ['word'], ['empty', 'string'], ['sentence', 'punctuation']]\n",
    "    with pytest.raises(KeyError):\n",
    "        lemmatize(df, 'non_existing_column')\n",
    "    df['non_string_column'] = [1, 2, 3, 4]\n",
    "    with pytest.raises(AttributeError):\n",
    "        lemmatize(df, 'non_string_column')\n",
    "\n",
    "\n",
    "def test_count_unique_words():\n",
    "    assert count_unique_words(['run', 'run', 'jump']) == 2\n",
    "    assert count_unique_words(['word']) == 1\n",
    "    assert count_unique_words([]) == 0\n",
    "    assert count_unique_words(['quick', 'brown', 'fox', 'jump', 'lazy', 'dog']) == 6\n",
    "    with pytest.raises(TypeError):\n",
    "        count_unique_words(\"not a list\")\n",
    "\n",
    "def test_vectorizer():\n",
    "    df = pd.DataFrame({\n",
    "        'prompt_id': ['1', '2'],\n",
    "        'prompt_lemmatized': [['run', 'run', 'jump'], ['word']],\n",
    "        'prompt_question_lemmatized': [['quick', 'brown', 'fox', 'jump', 'lazy', 'dog'], ['another', 'word']]\n",
    "    })\n",
    "    vectorizer_dict = vectorizer(df)\n",
    "    assert set(vectorizer_dict.keys()) == {'1', '2'}\n",
    "    assert set(vectorizer_dict['1'].keys()) == {'prompt', 'prompt_question'}\n",
    "    with pytest.raises(AttributeError):\n",
    "        vectorizer(\"not a DataFrame\")\n",
    "\n",
    "def test_vectorize():\n",
    "    vectorizer = CountVectorizer()\n",
    "    vectorizer.fit(['run jump jump', 'word'])\n",
    "    assert np.array_equal(vectorize(['run', 'run', 'jump'], vectorizer), np.array([[1, 2, 0]]))\n",
    "    assert np.array_equal(vectorize(['word'], vectorizer), np.array([[0, 0, 1]]))\n",
    "    assert np.array_equal(vectorize([], vectorizer), np.array([[0, 0, 0]]))\n",
    "    with pytest.raises(TypeError):\n",
    "        vectorize(\"not a list\", vectorizer)\n",
    "    with pytest.raises(AttributeError):\n",
    "        vectorize(['run', 'run', 'jump'], \"not a CountVectorizer\")\n",
    "\n",
    "def test_jaccard_similarity():\n",
    "    assert jaccard_similarity(np.array([[1, 1, 0]]), np.array([[1, 0, 0]])) == 0.5\n",
    "    assert jaccard_similarity(np.array([[1, 1, 1]]), np.array([[1, 1, 1]])) == 1.0\n",
    "    assert jaccard_similarity(np.array([[0, 0, 0]]), np.array([[1, 1, 1]])) == 0.0\n",
    "    assert jaccard_similarity(np.array([[1, 0, 1]]), np.array([[0, 1, 0]])) == 0.0\n",
    "    assert jaccard_similarity(np.array([[1, 2, 3]]), np.array([[1, 2, 3]])) == 1.0\n",
    "    with pytest.raises(ValueError):\n",
    "        jaccard_similarity(\"not a ndarray\", np.array([[1, 1, 0]]))\n",
    "    with pytest.raises(ValueError):\n",
    "        jaccard_similarity(np.array([[1, 1]]), np.array([[1, 1, 0]]))\n",
    "\n",
    "def test_ner():\n",
    "    assert ner(\"Apple is looking at buying U.K. startup for $1 billion\") == [('Apple', 'ORG'), ('U.K.', 'GPE'), ('$1 billion', 'MONEY')]\n",
    "    assert ner(\"He was born on 2000-01-01.\") == [('2000-01-01', 'DATE')]\n",
    "    assert ner(\"\") == []\n",
    "    with pytest.raises(ValueError):\n",
    "        ner(123)\n",
    "\n",
    "def test_jaccard_similarity_ner():\n",
    "    assert jaccard_similarity_ner([('Apple', 'ORG'), ('U.K.', 'GPE'), ('$1 billion', 'MONEY')], [('Apple', 'ORG'), ('U.K.', 'GPE')]) == 2/3\n",
    "    assert jaccard_similarity_ner([('2000-01-01', 'DATE')], [('2000-01-01', 'DATE')]) == 1.0\n",
    "    assert jaccard_similarity_ner([], [('2000-01-01', 'DATE')]) == 0.0\n",
    "    assert jaccard_similarity_ner([('Apple', 'ORG'), ('U.K.', 'GPE')], [('Google', 'ORG'), ('U.S.', 'GPE')]) == 0.0\n",
    "    with pytest.raises(TypeError):\n",
    "        jaccard_similarity_ner(\"not a list\", [('Apple', 'ORG'), ('U.K.', 'GPE')])\n",
    "\n",
    "def test_readability():\n",
    "    assert readability(\"The cat sat on the mat.\").equals(pd.Series([116.15, 2.4, -4.4]))\n",
    "    assert readability(\"This is a more complex sentence, with more words and more syllables.\").equals(pd.Series([84.68, 8.13, 6.9]))\n",
    "    assert readability(\"\").equals(pd.Series([206.84, 0.0, 0.0]))\n",
    "    with pytest.raises(TypeError):\n",
    "        readability(123)\n",
    "\n",
    "def test_cosine_similarity_sentiment():\n",
    "    assert cosine_similarity_sentiment((1, 0), (1, 0)) == 1.0\n",
    "    assert cosine_similarity_sentiment((1, 0), (0, 1)) == 0.0\n",
    "    assert cosine_similarity_sentiment((1, 0), (-1, 0)) == -1.0\n",
    "    assert cosine_similarity_sentiment((0, 0), (1, 0)) == 0.0\n",
    "    with pytest.raises(ValueError):\n",
    "        cosine_similarity_sentiment(\"not a tuple\", (1, 0))\n",
    "    with pytest.raises(ValueError):\n",
    "        cosine_similarity_sentiment((1, 0), (1, 0, 0))\n",
    "\n",
    "def test_sentiment():\n",
    "    df = pd.DataFrame({\n",
    "        'prompt_id': ['1', '2'],\n",
    "        'blob': [TextBlob('I love this product.'), TextBlob('I hate this product.')]\n",
    "    })\n",
    "    assert sentiment(df, 'I love this product.', '1') == 1.0\n",
    "    assert sentiment(df, 'I hate this product.', '2') == 1.0\n",
    "    assert sentiment(df, 'I love this product.', '2') == 0.1488603778620425\n",
    "    assert sentiment(df, 'I hate this product.', '1') == 0.1488603778620425\n",
    "    with pytest.raises(IndexError):\n",
    "        sentiment(df, 'I love this product.', '3')\n",
    "    with pytest.raises(TypeError):\n",
    "        sentiment(df, 123, '1')\n",
    "\n",
    "def test_tokenize():\n",
    "    assert tokenize(\"The quick brown fox jumps over the lazy dog.\") == 'DT JJ NN NN VBZ IN DT JJ NN .'\n",
    "    assert tokenize(\"No punctuation here\") == 'DT NN RB'\n",
    "    assert tokenize(\"\") == ''\n",
    "    with pytest.raises(TypeError):\n",
    "        tokenize(123)\n",
    "\n",
    "def test_tfidf_vectorizer():\n",
    "    df_prompt = pd.DataFrame({\n",
    "        'tokens': ['DT JJ NN NN VBZ IN DT JJ NN .', 'DT NN RB', '']\n",
    "    })\n",
    "    df_summaries = pd.DataFrame({\n",
    "        'tokens': ['DT JJ NN NN VBZ IN DT JJ NN .', 'DT NN RB', '']\n",
    "    })\n",
    "    vectorizer_tfidf = tfidf_vectorizer(df_prompt, df_summaries)\n",
    "    assert isinstance(vectorizer_tfidf, TfidfVectorizer)\n",
    "    assert vectorizer_tfidf.ngram_range == (4, 4)\n",
    "    with pytest.raises(TypeError):\n",
    "        tfidf_vectorizer(\"not a DataFrame\", df_summaries)\n",
    "    with pytest.raises(TypeError):\n",
    "        tfidf_vectorizer(df_prompt, \"not a DataFrame\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amelioration_projet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
