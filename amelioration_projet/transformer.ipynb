{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_prompt = pd.read_csv('commonlit-evaluate-student-summaries/prompts_train.csv')\n",
    "df_train_summaries = pd.read_csv('commonlit-evaluate-student-summaries/summaries_train.csv')\n",
    "df_train = df_train_summaries.merge(df_train_prompt, on='prompt_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_stopwords(text: str) -> int:\n",
    "    stopword_list = set(stopwords.words('english'))\n",
    "    words = text.split()\n",
    "    stopwords_count = sum(1 for word in words if word.lower() in stopword_list)\n",
    "    return stopwords_count\n",
    "\n",
    "# Count the punctuations in the text.\n",
    "# punctuation_set -> !\"#$%&'()*+, -./:;<=>?@[\\]^_`{|}~\n",
    "def count_punctuation(text: str) -> int:\n",
    "    punctuation_set = set(string.punctuation)\n",
    "    punctuation_count = sum(1 for char in text if char in punctuation_set)\n",
    "    return punctuation_count\n",
    "\n",
    "# Count the digits in the text.\n",
    "def count_numbers(text: str) -> int:\n",
    "    numbers = re.findall(r'\\d+', text)\n",
    "    numbers_count = len(numbers)\n",
    "    return numbers_count\n",
    "\n",
    "# This function applies all the above preprocessing functions on a text feature.\n",
    "def feature_engineer(dataframe: pd.DataFrame, feature: str = 'text') -> pd.DataFrame:\n",
    "    dataframe[f'{feature}_word_cnt'] = dataframe[feature].apply(lambda x: len(x.split(' ')))\n",
    "    dataframe[f'{feature}_length'] = dataframe[feature].apply(lambda x: len(x))\n",
    "    dataframe[f'{feature}_stopword_cnt'] = dataframe[feature].apply(lambda x: count_stopwords(x))\n",
    "    dataframe[f'{feature}_punct_cnt'] = dataframe[feature].apply(lambda x: count_punctuation(x))\n",
    "    dataframe[f'{feature}_number_cnt'] = dataframe[feature].apply(lambda x: count_numbers(x))\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df = feature_engineer(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, questions, summaries, grades):\n",
    "        self.texts = texts\n",
    "        self.questions = questions\n",
    "        self.summaries = summaries\n",
    "        self.grades = grades\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        question = self.questions[idx]\n",
    "        summary = self.summaries[idx]\n",
    "        grade = self.grades[idx]\n",
    "\n",
    "        # We concatenate the text, question and summary and separate them with the [SEP] token\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text + ' [SEP] ' + question + ' [SEP] ' + summary,\n",
    "            add_special_tokens=True,\n",
    "            max_length=512,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        input_ids = inputs['input_ids'].squeeze()\n",
    "        attention_mask = inputs['attention_mask'].squeeze()\n",
    "\n",
    "        return input_ids, attention_mask, grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = preprocessed_df['prompt_text']\n",
    "questions = preprocessed_df['prompt_question']\n",
    "summaries = preprocessed_df['text']\n",
    "grades1 = preprocessed_df['content']\n",
    "grades2 = preprocessed_df['wording']\n",
    "\n",
    "# Create datasets\n",
    "dataset1 = TextDataset(texts, questions, summaries, grades1)\n",
    "dataset2 = TextDataset(texts, questions, summaries, grades2)\n",
    "\n",
    "# Create dataloaders\n",
    "train_dataloader1 = DataLoader(dataset1, batch_size=32, shuffle=True)\n",
    "train_dataloader2 = DataLoader(dataset2, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch.nn as nn\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('prajjwal1/bert-tiny')\n",
    "base_model = AutoModel.from_pretrained('prajjwal1/bert-tiny')\n",
    "\n",
    "class GradePredictor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GradePredictor, self).__init__()\n",
    "        self.base_model = base_model\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.linear = nn.Linear(base_model.config.hidden_size, 1)  # Predicting one grade\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.base_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        out = self.dropout(outputs.last_hidden_state[:, 0, :])\n",
    "        return self.linear(out)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Instantiate two separate models\n",
    "model1 = GradePredictor().to(device)\n",
    "model2 = GradePredictor().to(device)\n",
    "\n",
    "# Define loss function - since we're predicting a single grade in each model, we can use Mean Squared Error (MSE)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Define optimizers\n",
    "optimizer1 = torch.optim.Adam(model1.parameters(), lr=1e-5)\n",
    "optimizer2 = torch.optim.Adam(model2.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def trainer(model, num_epochs, train_dataloader, optimizer):\n",
    "    \n",
    "    criterion = nn.MSELoss()  # or whatever loss function is appropriate for your task\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Initialize a dictionary to hold metrics\n",
    "    metrics = {'train_loss': [], 'mse': [], 'rmse': [], 'mae': [], 'r2': [], 'lr': []}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training loop for model\n",
    "        total_loss = 0  # Keep track of the total loss\n",
    "        all_labels = []\n",
    "        all_predictions = []\n",
    "\n",
    "        for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch+1}\"):\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Get input data and labels\n",
    "            input_ids, attention_mask, labels = batch\n",
    "            labels = labels.float().to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(input_ids=input_ids.to(device), attention_mask=attention_mask.to(device)).squeeze()\n",
    "            outputs = outputs.unsqueeze(0) if outputs.dim() == 0 else outputs\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            # Move labels and outputs to CPU\n",
    "            labels = labels.detach().cpu().numpy()\n",
    "            outputs = outputs.detach().cpu().numpy()\n",
    "\n",
    "            # Store labels and predictions\n",
    "            all_labels.append(labels)\n",
    "            all_predictions.append(outputs)\n",
    "\n",
    "        # Concatenate all labels and predictions\n",
    "        all_labels = np.concatenate(all_labels, axis=0)\n",
    "        all_predictions = np.concatenate(all_predictions, axis=0)\n",
    "\n",
    "        # Calculate metrics\n",
    "        mse = mean_squared_error(all_labels, all_predictions)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(all_labels, all_predictions)\n",
    "        r2 = r2_score(all_labels, all_predictions)\n",
    "        lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "        # Save metrics\n",
    "        metrics['train_loss'].append(total_loss / len(train_dataloader))\n",
    "        metrics['mse'].append(mse)\n",
    "        metrics['rmse'].append(rmse)\n",
    "        metrics['mae'].append(mae)\n",
    "        metrics['r2'].append(r2)\n",
    "        metrics['lr'].append(lr)\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 224/224 [01:33<00:00,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Total Loss:258.77339351177216, Loss:1.16, MSE: 1.16, RMSE: 1.07, MAE: 0.85, R2: -0.06, LR: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 224/224 [01:34<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Total Loss:258.5090417563915, Loss:1.15, MSE: 1.15, RMSE: 1.07, MAE: 0.85, R2: -0.06, LR: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 224/224 [01:35<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Total Loss:253.74255380034447, Loss:1.13, MSE: 1.13, RMSE: 1.06, MAE: 0.84, R2: -0.04, LR: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 224/224 [01:34<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Total Loss:252.04837596416473, Loss:1.13, MSE: 1.13, RMSE: 1.06, MAE: 0.83, R2: -0.03, LR: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 224/224 [01:35<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Total Loss:252.09599813818932, Loss:1.13, MSE: 1.13, RMSE: 1.06, MAE: 0.84, R2: -0.03, LR: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 224/224 [01:35<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Total Loss:249.9986026585102, Loss:1.12, MSE: 1.12, RMSE: 1.06, MAE: 0.83, R2: -0.02, LR: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 224/224 [01:36<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Total Loss:248.5925725698471, Loss:1.11, MSE: 1.11, RMSE: 1.05, MAE: 0.83, R2: -0.02, LR: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 224/224 [01:34<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Total Loss:249.78878486156464, Loss:1.12, MSE: 1.12, RMSE: 1.06, MAE: 0.83, R2: -0.02, LR: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 224/224 [01:34<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Total Loss:249.08163154125214, Loss:1.11, MSE: 1.11, RMSE: 1.05, MAE: 0.83, R2: -0.02, LR: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 224/224 [01:35<00:00,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Total Loss:245.82104796171188, Loss:1.10, MSE: 1.10, RMSE: 1.05, MAE: 0.82, R2: -0.01, LR: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_loss': [1.15523836389184,\n",
       "  1.154058222126748,\n",
       "  1.132779258037252,\n",
       "  1.1252159641257353,\n",
       "  1.1254285631169165,\n",
       "  1.1160651904397778,\n",
       "  1.109788270401103,\n",
       "  1.1151285038462706,\n",
       "  1.1119715693805898,\n",
       "  1.0974153926862138],\n",
       " 'mse': [1.155411,\n",
       "  1.1541831,\n",
       "  1.1329217,\n",
       "  1.1252489,\n",
       "  1.1253606,\n",
       "  1.1160774,\n",
       "  1.1096829,\n",
       "  1.1153201,\n",
       "  1.112009,\n",
       "  1.0974799],\n",
       " 'rmse': [1.0749005,\n",
       "  1.0743291,\n",
       "  1.0643879,\n",
       "  1.0607775,\n",
       "  1.0608301,\n",
       "  1.0564456,\n",
       "  1.053415,\n",
       "  1.0560871,\n",
       "  1.0545183,\n",
       "  1.0476068],\n",
       " 'mae': [0.8476144,\n",
       "  0.8461545,\n",
       "  0.84011036,\n",
       "  0.8345508,\n",
       "  0.8369054,\n",
       "  0.8297773,\n",
       "  0.83029306,\n",
       "  0.8316072,\n",
       "  0.83054125,\n",
       "  0.8249168],\n",
       " 'r2': [-0.061095504765936726,\n",
       "  -0.0599678385696667,\n",
       "  -0.04044186253710058,\n",
       "  -0.033395409222010786,\n",
       "  -0.033498072233478116,\n",
       "  -0.02497265764670864,\n",
       "  -0.019100208054818824,\n",
       "  -0.024277156525449595,\n",
       "  -0.021236359451172193,\n",
       "  -0.00789318271990247],\n",
       " 'lr': [1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05]}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer(model1, 10, train_dataloader1, optimizer1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(dataloader, model):\n",
    "    # Make sure the model is in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    all_predictions = []\n",
    "\n",
    "    # Iterate over batches\n",
    "    for batch in dataloader:\n",
    "        # Get input data and labels\n",
    "        input_ids, attention_mask, labels = batch\n",
    "\n",
    "        # Move data to the same device as the model\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "\n",
    "        # Get the model's predictions\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        # Move predictions to CPU\n",
    "        predictions = outputs.detach().cpu().numpy()\n",
    "\n",
    "        # Store predictions\n",
    "        all_predictions.append(predictions)\n",
    "\n",
    "    # Concatenate all predictions\n",
    "    all_predictions = np.concatenate(all_predictions, axis=0)\n",
    "\n",
    "    return all_predictions\n",
    "\n",
    "# Use the function to get predictions\n",
    "predictions1 = predict(train_dataloader1, model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div id=e7071076-f746-4a67-b09d-fba359e99c70 style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands?.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('e7071076-f746-4a67-b09d-fba359e99c70').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.205683</td>\n",
       "      <td>0.042856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.272894</td>\n",
       "      <td>0.042481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.205683</td>\n",
       "      <td>0.286839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.567975</td>\n",
       "      <td>0.286839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.910596</td>\n",
       "      <td>0.042481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7160</th>\n",
       "      <td>-0.981265</td>\n",
       "      <td>0.042856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7161</th>\n",
       "      <td>-0.511077</td>\n",
       "      <td>0.042481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7162</th>\n",
       "      <td>-0.834946</td>\n",
       "      <td>0.042856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7163</th>\n",
       "      <td>-0.157460</td>\n",
       "      <td>0.286839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7164</th>\n",
       "      <td>-0.393310</td>\n",
       "      <td>0.042481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "       content      pred\n",
       "0     0.205683  0.042856\n",
       "1     3.272894  0.042481\n",
       "2     0.205683  0.286839\n",
       "3     0.567975  0.286839\n",
       "4    -0.910596  0.042481\n",
       "...        ...       ...\n",
       "7160 -0.981265  0.042856\n",
       "7161 -0.511077  0.042481\n",
       "7162 -0.834946  0.042856\n",
       "7163 -0.157460  0.286839\n",
       "7164 -0.393310  0.042481\n",
       "\n",
       "[7165 rows x 2 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare = pd.DataFrame(grades1)\n",
    "compare['pred'] = predictions1\n",
    "compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div id=d267269f-bc75-437a-81cc-bb49e7a27e2f style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands?.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('d267269f-bc75-437a-81cc-bb49e7a27e2f').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7165.000000</td>\n",
       "      <td>7165.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.014853</td>\n",
       "      <td>0.116956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.043569</td>\n",
       "      <td>0.092002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.729859</td>\n",
       "      <td>0.042481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.799545</td>\n",
       "      <td>0.042481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.093814</td>\n",
       "      <td>0.042856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.499660</td>\n",
       "      <td>0.173562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.900326</td>\n",
       "      <td>0.286839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "           content         pred\n",
       "count  7165.000000  7165.000000\n",
       "mean     -0.014853     0.116956\n",
       "std       1.043569     0.092002\n",
       "min      -1.729859     0.042481\n",
       "25%      -0.799545     0.042481\n",
       "50%      -0.093814     0.042856\n",
       "75%       0.499660     0.173562\n",
       "max       3.900326     0.286839"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "grades1.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
